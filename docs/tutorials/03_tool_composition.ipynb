{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 3: Tool Composition with Lenses\n",
    "\n",
    "**Goal**: Learn to build complex policies by composing tools mathematically\n",
    "\n",
    "**Time**: 20 minutes\n",
    "\n",
    "**Prerequisites**: Tutorials 1 & 2\n",
    "\n",
    "---\n",
    "\n",
    "## Why Composition?\n",
    "\n",
    "Real tasks require multiple tools working together:\n",
    "- Fetch data from API → Parse JSON → Validate schema → Write to database\n",
    "- Read file → Extract text → Summarize → Send email\n",
    "- Check service health → If healthy, deploy → If unhealthy, rollback\n",
    "\n",
    "Standard approaches chain tools with error-prone if/else logic. LRS uses **categorical composition** - tools as mathematical morphisms that compose automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory: ToolLens\n",
    "\n",
    "In LRS, tools are **lenses** from category theory.\n",
    "\n",
    "A lens has two operations:\n",
    "1. **get**: Execute the tool (state → result)\n",
    "2. **set**: Update belief state (state × observation → new_state)\n",
    "\n",
    "**Key property**: Lenses compose via the `>>` operator\n",
    "\n",
    "```python\n",
    "pipeline = tool_a >> tool_b >> tool_c\n",
    "```\n",
    "\n",
    "This creates a new lens where:\n",
    "- Data flows forward through get operations\n",
    "- Belief updates flow backward through set operations\n",
    "- Errors propagate automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lrs.core.lens import ToolLens, ExecutionResult\n",
    "import json\n",
    "import requests\n",
    "\n",
    "# Example: Build a weather data pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Define Individual Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeatherAPITool(ToolLens):\n",
    "    \"\"\"Fetch weather data from API\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            name=\"weather_api\",\n",
    "            input_schema={'type': 'object', 'required': ['city']},\n",
    "            output_schema={'type': 'string'}  # JSON string\n",
    "        )\n",
    "    \n",
    "    def get(self, state: dict) -> ExecutionResult:\n",
    "        self.call_count += 1\n",
    "        city = state.get('city', 'San Francisco')\n",
    "        \n",
    "        # Simulate API call\n",
    "        # In production: response = requests.get(f\"api.weather.com/{city}\")\n",
    "        mock_response = json.dumps({\n",
    "            'city': city,\n",
    "            'temperature_f': 72,\n",
    "            'conditions': 'sunny'\n",
    "        })\n",
    "        \n",
    "        print(f\"  ✓ Fetched weather for {city}\")\n",
    "        return ExecutionResult(\n",
    "            success=True,\n",
    "            value=mock_response,\n",
    "            error=None,\n",
    "            prediction_error=0.1  # Low error for successful API call\n",
    "        )\n",
    "    \n",
    "    def set(self, state: dict, observation: str) -> dict:\n",
    "        \"\"\"Update state with raw API response\"\"\"\n",
    "        return {**state, 'raw_weather_data': observation}\n",
    "\n",
    "\n",
    "class JSONParserTool(ToolLens):\n",
    "    \"\"\"Parse JSON string\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            name=\"json_parser\",\n",
    "            input_schema={'type': 'object', 'required': ['raw_weather_data']},\n",
    "            output_schema={'type': 'object'}\n",
    "        )\n",
    "    \n",
    "    def get(self, state: dict) -> ExecutionResult:\n",
    "        self.call_count += 1\n",
    "        raw_data = state.get('raw_weather_data', '{}')\n",
    "        \n",
    "        try:\n",
    "            parsed = json.loads(raw_data)\n",
    "            print(f\"  ✓ Parsed JSON successfully\")\n",
    "            return ExecutionResult(True, parsed, None, 0.05)\n",
    "        except json.JSONDecodeError as e:\n",
    "            self.failure_count += 1\n",
    "            print(f\"  ✗ JSON parse failed: {e}\")\n",
    "            return ExecutionResult(False, None, str(e), 0.95)\n",
    "    \n",
    "    def set(self, state: dict, observation: dict) -> dict:\n",
    "        return {**state, 'parsed_weather': observation}\n",
    "\n",
    "\n",
    "class TemperatureConverterTool(ToolLens):\n",
    "    \"\"\"Convert Fahrenheit to Celsius\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            name=\"temp_converter\",\n",
    "            input_schema={'type': 'object', 'required': ['parsed_weather']},\n",
    "            output_schema={'type': 'number'}\n",
    "        )\n",
    "    \n",
    "    def get(self, state: dict) -> ExecutionResult:\n",
    "        self.call_count += 1\n",
    "        weather = state.get('parsed_weather', {})\n",
    "        temp_f = weather.get('temperature_f', 0)\n",
    "        \n",
    "        temp_c = (temp_f - 32) * 5 / 9\n",
    "        print(f\"  ✓ Converted {temp_f}°F to {temp_c:.1f}°C\")\n",
    "        \n",
    "        return ExecutionResult(True, temp_c, None, 0.0)  # Math is deterministic\n",
    "    \n",
    "    def set(self, state: dict, observation: float) -> dict:\n",
    "        return {**state, 'temperature_celsius': observation}\n",
    "\n",
    "\n",
    "class ReportGeneratorTool(ToolLens):\n",
    "    \"\"\"Generate weather report\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            name=\"report_generator\",\n",
    "            input_schema={'type': 'object', 'required': ['parsed_weather', 'temperature_celsius']},\n",
    "            output_schema={'type': 'string'}\n",
    "        )\n",
    "    \n",
    "    def get(self, state: dict) -> ExecutionResult:\n",
    "        self.call_count += 1\n",
    "        weather = state.get('parsed_weather', {})\n",
    "        temp_c = state.get('temperature_celsius', 0)\n",
    "        \n",
    "        report = f\"\"\"\n",
    "Weather Report for {weather.get('city', 'Unknown')}:\n",
    "Conditions: {weather.get('conditions', 'Unknown')}\n",
    "Temperature: {temp_c:.1f}°C\n",
    "\"\"\".strip()\n",
    "        \n",
    "        print(f\"  ✓ Generated report\")\n",
    "        return ExecutionResult(True, report, None, 0.05)\n",
    "    \n",
    "    def set(self, state: dict, observation: str) -> dict:\n",
    "        return {**state, 'final_report': observation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Compose Tools with >>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline: API → Parse → Convert → Report\n",
    "weather_pipeline = (\n",
    "    WeatherAPITool() >> \n",
    "    JSONParserTool() >> \n",
    "    TemperatureConverterTool() >> \n",
    "    ReportGeneratorTool()\n",
    ")\n",
    "\n",
    "print(\"Pipeline created:\")\n",
    "print(\"  WeatherAPI → JSONParser → TempConverter → ReportGenerator\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Execute the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute entire pipeline with single get() call\n",
    "print(\"\\nExecuting pipeline...\\n\")\n",
    "\n",
    "initial_state = {'city': 'New York'}\n",
    "result = weather_pipeline.get(initial_state)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"RESULT\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Success: {result.success}\")\n",
    "print(f\"\\n{result.value}\")\n",
    "print(f\"\\nPrediction error: {result.prediction_error:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What Just Happened?\n",
    "\n",
    "The `>>` operator created a **composed lens**. When you call `get()`:\n",
    "\n",
    "1. Data flows **forward**:\n",
    "   - WeatherAPI fetches JSON string\n",
    "   - JSONParser receives string, outputs dict\n",
    "   - TempConverter receives dict, outputs float\n",
    "   - ReportGenerator receives dict + float, outputs string\n",
    "\n",
    "2. State updates flow **backward**:\n",
    "   - Each `set()` is called in reverse order\n",
    "   - Final state contains all intermediate values\n",
    "\n",
    "3. Errors propagate automatically:\n",
    "   - If any tool fails, pipeline short-circuits\n",
    "   - Error message bubbles up\n",
    "   - Prediction error reflects failure point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment: Break the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BrokenJSONParser(ToolLens):\n",
    "    \"\"\"Parser that always fails\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__(name=\"broken_parser\", input_schema={}, output_schema={})\n",
    "    \n",
    "    def get(self, state: dict) -> ExecutionResult:\n",
    "        self.call_count += 1\n",
    "        self.failure_count += 1\n",
    "        print(\"  ✗ Parser crashed!\")\n",
    "        return ExecutionResult(False, None, \"Parser crashed\", 0.95)\n",
    "    \n",
    "    def set(self, state: dict, obs: any) -> dict:\n",
    "        return state\n",
    "\n",
    "# Create broken pipeline\n",
    "broken_pipeline = (\n",
    "    WeatherAPITool() >> \n",
    "    BrokenJSONParser() >>  # This will fail\n",
    "    TemperatureConverterTool() >> \n",
    "    ReportGeneratorTool()\n",
    ")\n",
    "\n",
    "print(\"\\nExecuting broken pipeline...\\n\")\n",
    "result = broken_pipeline.get({'city': 'London'})\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"Success: {result.success}\")\n",
    "print(f\"Error: {result.error}\")\n",
    "print(f\"Prediction error: {result.prediction_error:.3f}\")\n",
    "print(\"\\n⚠️ Pipeline short-circuited at failure point!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced: Fallback Chains with Natural Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lrs.core.registry import ToolRegistry\n",
    "\n",
    "# Create registry\n",
    "registry = ToolRegistry()\n",
    "\n",
    "# Register parser with alternative\n",
    "class XMLParserTool(ToolLens):\n",
    "    \"\"\"Alternative parser (XML)\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__(name=\"xml_parser\", input_schema={}, output_schema={})\n",
    "    \n",
    "    def get(self, state: dict) -> ExecutionResult:\n",
    "        print(\"  ℹ️  Using XML parser as fallback\")\n",
    "        # Mock XML parsing\n",
    "        return ExecutionResult(True, {'city': 'Fallback', 'temperature_f': 68}, None, 0.2)\n",
    "    \n",
    "    def set(self, state: dict, obs: dict) -> dict:\n",
    "        return {**state, 'parsed_weather': obs}\n",
    "\n",
    "# Register both parsers\n",
    "json_parser = JSONParserTool()\n",
    "xml_parser = XMLParserTool()\n",
    "\n",
    "registry.register(json_parser, alternatives=[\"xml_parser\"])\n",
    "registry.register(xml_parser)\n",
    "\n",
    "print(\"\\nRegistered parsers:\")\n",
    "print(\"  - json_parser (primary)\")\n",
    "print(\"  - xml_parser (fallback)\")\n",
    "\n",
    "# When JSON parser fails, registry suggests XML parser\n",
    "alternatives = registry.find_alternatives(\"json_parser\")\n",
    "print(f\"\\nAlternatives for json_parser: {alternatives}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integration with LRS Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lrs import create_lrs_agent\n",
    "from unittest.mock import Mock\n",
    "\n",
    "# Create LRS agent with composed tools\n",
    "tools = [\n",
    "    weather_pipeline,  # The entire pipeline as one tool!\n",
    "    # Or individual tools for more flexibility\n",
    "    # WeatherAPITool(),\n",
    "    # JSONParserTool(),\n",
    "    # TemperatureConverterTool(),\n",
    "]\n",
    "\n",
    "mock_llm = Mock()\n",
    "\n",
    "agent = create_lrs_agent(mock_llm, tools)\n",
    "\n",
    "print(\"\\n✅ LRS agent created with composed pipeline\")\n",
    "print(\"\\nThe agent can now:\")\n",
    "print(\"  - Execute the full weather pipeline\")\n",
    "print(\"  - Track prediction errors at each stage\")\n",
    "print(\"  - Adapt if any component fails\")\n",
    "print(\"  - Automatically try alternatives via registry\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **Tools are lenses**: Two operations (get, set)\n",
    "2. **Composition via >>**: Creates new lenses automatically\n",
    "3. **Automatic error propagation**: Failures short-circuit\n",
    "4. **State threading**: Each tool updates belief state\n",
    "5. **Fallback chains**: Registry provides alternatives\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- **Tutorial 4**: Run the Chaos Scriptorium benchmark\n",
    "- **Tutorial 5**: Integrate real LLMs for policy generation\n",
    "- **Tutorial 6**: Monitor agents with the dashboard\n",
    "\n",
    "## Exercise\n",
    "\n",
    "Build your own pipeline:\n",
    "1. File reader → Text extractor → Summarizer → Email sender\n",
    "2. Add a fallback for each component\n",
    "3. Test with both success and failure scenarios"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
